{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "UserWarning: Failed to load custom C++ ops. Running on CPU mode Only!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "file \"/home/da2986/tennis_tracker/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\" does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/da2986/tennis_tracker/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/da2986/tennis_tracker/GroundingDINO/groundingdino_swint_ogc.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# model = torch.compile(model)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/tennis_tracker/GroundingDINO/groundingdino/util/inference.py:32\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_config_path, model_checkpoint_path, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[1;32m     30\u001b[0m     model_config_path: \u001b[38;5;28mstr\u001b[39m, model_checkpoint_path: \u001b[38;5;28mstr\u001b[39m, device: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m ):\n\u001b[0;32m---> 32\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mSLConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     args\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     34\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_model(args)\n",
      "File \u001b[0;32m~/Desktop/tennis_tracker/GroundingDINO/groundingdino/util/slconfig.py:185\u001b[0m, in \u001b[0;36mSLConfig.fromfile\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(filename):\n\u001b[0;32m--> 185\u001b[0m     cfg_dict, cfg_text \u001b[38;5;241m=\u001b[39m \u001b[43mSLConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file2dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SLConfig(cfg_dict, cfg_text\u001b[38;5;241m=\u001b[39mcfg_text, filename\u001b[38;5;241m=\u001b[39mfilename)\n",
      "File \u001b[0;32m~/Desktop/tennis_tracker/GroundingDINO/groundingdino/util/slconfig.py:79\u001b[0m, in \u001b[0;36mSLConfig._file2dict\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_file2dict\u001b[39m(filename):\n\u001b[1;32m     78\u001b[0m     filename \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mabspath(osp\u001b[38;5;241m.\u001b[39mexpanduser(filename))\n\u001b[0;32m---> 79\u001b[0m     \u001b[43mcheck_file_exist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m temp_config_dir:\n",
      "File \u001b[0;32m~/Desktop/tennis_tracker/GroundingDINO/groundingdino/util/slconfig.py:23\u001b[0m, in \u001b[0;36mcheck_file_exist\u001b[0;34m(filename, msg_tmpl)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_file_exist\u001b[39m(filename, msg_tmpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m osp\u001b[38;5;241m.\u001b[39misfile(filename):\n\u001b[0;32m---> 23\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg_tmpl\u001b[38;5;241m.\u001b[39mformat(filename))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: file \"/home/da2986/tennis_tracker/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\" does not exist"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from groundingdino.util.inference import batch_predict, load_image_quarters, load_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tennis_tracker.download_data.extract_keypoints import (\n",
    "    read_json_file,\n",
    "    write_to_json_file,\n",
    ")\n",
    "from tennis_tracker.player_location.homography import transform_points\n",
    "\n",
    "\n",
    "def output_point(m: np.array, points: np.array) -> list:\n",
    "    \"\"\"points should be in shape (-1, 1, 2)\"\"\"\n",
    "    outputs = cv2.perspectiveTransform(points, m)\n",
    "    # output will be -1, 1, 2\n",
    "    return outputs.reshape(-1, 2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model = load_model(\n",
    "        \"/home/da2986/tennis_tracker/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\",\n",
    "        \"/home/da2986/tennis_tracker/GroundingDINO/groundingdino_swint_ogc.pth\",\n",
    "    )\n",
    "    # model = torch.compile(model)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    TEXT_PROMPT = \"tennis ball\"\n",
    "    BOX_TRESHOLD = 0.35\n",
    "    TEXT_TRESHOLD = 0.25\n",
    "    JSON_PATH = (\n",
    "        \"/home/da2986/tennis_tracker/tennis_tracker/pseudo_label/clean_labels.json\"\n",
    "    )\n",
    "\n",
    "    data = read_json_file(JSON_PATH)\n",
    "    img_paths = [img_path for img_path in data.keys()]\n",
    "\n",
    "    batch_size = 1\n",
    "    OUTPUT_JSON_PATH = \"/home/da2986/tennis_tracker/tennis_tracker/ball_tracking/labels.json\"\n",
    "    \n",
    "    if os.path.exists(OUTPUT_JSON_PATH):\n",
    "        os.remove(OUTPUT_JSON_PATH)\n",
    "        \n",
    "    img_paths = img_paths[:10]\n",
    "\n",
    "    for i in tqdm(range(0, len(img_paths), batch_size)):\n",
    "        batch_images = img_paths[i : i + batch_size]\n",
    "        loaded_images = []\n",
    "        for image in batch_images:\n",
    "            image_source, image = load_image_quarters(image)\n",
    "            loaded_images.extend(image)\n",
    "        input_images = torch.stack(loaded_images)\n",
    "        boxes, logits, boxes_to_im = batch_predict(\n",
    "            model=model,\n",
    "            preprocessed_images=input_images,\n",
    "            caption=TEXT_PROMPT,\n",
    "            box_threshold=BOX_TRESHOLD,\n",
    "            text_threshold=TEXT_TRESHOLD,\n",
    "            device=device,\n",
    "        )\n",
    "        lines = []\n",
    "        for im_num in range(len(batch_images)):\n",
    "            # get all the boxes that correspond to this image\n",
    "            im_boxes = boxes[torch.Tensor(boxes_to_im) == im_num]\n",
    "            all_boxes = []\n",
    "            if len(im_boxes) > 0:\n",
    "                for box in im_boxes:\n",
    "                    if im_num % 4 == 0:\n",
    "                        pass\n",
    "                    elif im_num % 4 == 1:\n",
    "                        box[0] += 0.5\n",
    "                    elif im_num % 4 == 2:\n",
    "                        box[1] += 0.5\n",
    "                    elif im_num % 4 == 3:\n",
    "                        box[0] += 0.5\n",
    "                        box[1] += 0.5\n",
    "                    box[2] *= 0.5\n",
    "                    box[3] *= 0.5\n",
    "                    all_boxes.append(f\"0 {box[0]} {box[1]} {box[2]} {box[3]}\")\n",
    "                    break\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "def plot_box(box: list, image: np.array):\n",
    "    cx, cy, w, h = box\n",
    "    image_height, image_width, _ = image.shape\n",
    "    x1 = int((cx - w/2) * image_width)\n",
    "    x2 = int((cx + w/2) * image_width)\n",
    "    y1 = int((cy - h/2) * image_height)\n",
    "    y2 = int((cy + h/2) * image_height) \n",
    "    plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, color='red', fill=False))\n",
    "    plt.show()\n",
    "            \n",
    "plt.imshow(image_source)\n",
    "plt.show()\n",
    "\n",
    "plot_box(boxes[0], image_source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
